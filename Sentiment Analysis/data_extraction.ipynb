{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "from datetime import datetime as dt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"Ijfzy88liEKe7iGMHtKORg\"\n",
    "client_secret = \"3kt2_MM5k0AF8PIFXVh32lAr1xEhXg\"\n",
    "user_agent = \"Scraper 1.0 by /u/charltonxqh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_reddit_client(client_id, client_secret, user_agent):\n",
    "  return praw.Reddit(client_id=client_id, client_secret=client_secret, user_agent=user_agent)\n",
    "\n",
    "def extract_comments_voo(reddit, subreddit_name, keyword, limit=1000):\n",
    "    \"\"\"\n",
    "    Extract comments from the specified subreddit for submissions containing the keyword 'VOO'.\n",
    "    Limit the number of comments to 1000.\n",
    "    \"\"\"\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    comments_data = []\n",
    "    comment_count = 0\n",
    "\n",
    "    for submission in subreddit.search(keyword, sort='new'):\n",
    "        # Check if the submission title contains the keyword\n",
    "        if keyword.lower() in submission.title.lower():\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            for comment in submission.comments.list():\n",
    "                if comment_count >= limit:\n",
    "                    break\n",
    "\n",
    "                comment_data = {\n",
    "                    'id': comment.id,\n",
    "                    'created_utc': dt.fromtimestamp(comment.created_utc),\n",
    "                    'permalink': comment.permalink,\n",
    "                    'body': comment.body,\n",
    "                    'author': str(comment.author),\n",
    "                    'score': comment.score,\n",
    "                    'subreddit': str(comment.subreddit)\n",
    "                }\n",
    "                comments_data.append(comment_data)\n",
    "                comment_count += 1\n",
    "\n",
    "        if comment_count >= limit:\n",
    "            break\n",
    "\n",
    "    return comments_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id         created_utc  \\\n",
      "0  kwczgum 2024-03-25 00:51:21   \n",
      "1  kwdbk25 2024-03-25 02:02:08   \n",
      "2  kwd6nto 2024-03-25 01:33:43   \n",
      "3  kwei3zo 2024-03-25 06:17:54   \n",
      "4  kwei97t 2024-03-25 06:18:48   \n",
      "\n",
      "                                           permalink  \\\n",
      "0  /r/ETFs/comments/1bmoom7/diversifying_my_ira_f...   \n",
      "1  /r/ETFs/comments/1bmoom7/diversifying_my_ira_f...   \n",
      "2  /r/ETFs/comments/1bmoom7/diversifying_my_ira_f...   \n",
      "3  /r/ETFs/comments/1bmoom7/diversifying_my_ira_f...   \n",
      "4  /r/ETFs/comments/1bmoom7/diversifying_my_ira_f...   \n",
      "\n",
      "                                                body            author  score  \\\n",
      "0  Iâ€™m retired and hold a 100% equities portfolio...  AlgoTradingQuant      7   \n",
      "1  The more experienced investors recommend a ble...   foldinthechhese      3   \n",
      "2  It isn't *risky* by any stretch. You're exclud...      SirChetManly      2   \n",
      "3                                    Enough said :))         ZAROV8862      2   \n",
      "4                                     Makes sense...         ZAROV8862      2   \n",
      "\n",
      "  subreddit  \n",
      "0      ETFs  \n",
      "1      ETFs  \n",
      "2      ETFs  \n",
      "3      ETFs  \n",
      "4      ETFs  \n"
     ]
    }
   ],
   "source": [
    "# Initialize and extract comments\n",
    "reddit = setup_reddit_client(client_id, client_secret, user_agent)\n",
    "comments = extract_comments_voo(reddit, \"ETFs\", \"VOO\")\n",
    "df = pd.DataFrame(comments)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 925 entries, 0 to 924\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   id           925 non-null    object        \n",
      " 1   created_utc  925 non-null    datetime64[ns]\n",
      " 2   permalink    925 non-null    object        \n",
      " 3   body         925 non-null    object        \n",
      " 4   author       925 non-null    object        \n",
      " 5   score        925 non-null    int64         \n",
      " 6   subreddit    925 non-null    object        \n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 50.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
