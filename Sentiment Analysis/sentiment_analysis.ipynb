{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our cleaned dataset. We can start do our sentiment analysis on the comments about ```VOO``` from Subreddit ```r/ETFs```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.count_parameters import count_parameters\n",
    "from functions.evaluate import evaluate\n",
    "from functions.get_accuracy import get_accuracy\n",
    "from functions.get_collate_fn import get_collate_fn\n",
    "from functions.get_data_loader import get_data_loader\n",
    "from functions.predict_sentiment import predict_sentiment\n",
    "from functions.split_data import split_data\n",
    "from functions.train import train\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "import tqdm\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 8888\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>ID</th>\n",
       "      <th>CREATED_UTC</th>\n",
       "      <th>PERMALINK</th>\n",
       "      <th>BODY</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>SUBREDDIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lotterytix</td>\n",
       "      <td>kwh3sji</td>\n",
       "      <td>2024-03-25 20:10:23</td>\n",
       "      <td>/r/ETFs/comments/1bmqbxg/new_to_investing_is_v...</td>\n",
       "      <td>Maybe consider VOO and a mid/small cap value f...</td>\n",
       "      <td>1</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AlgoTradingQuant</td>\n",
       "      <td>kwczgum</td>\n",
       "      <td>2024-03-25 00:51:21</td>\n",
       "      <td>/r/ETFs/comments/1bmoom7/diversifying_my_ira_f...</td>\n",
       "      <td>I’m retired and hold a 100% equities portfolio...</td>\n",
       "      <td>8</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foldinthechhese</td>\n",
       "      <td>kwdbk25</td>\n",
       "      <td>2024-03-25 02:02:08</td>\n",
       "      <td>/r/ETFs/comments/1bmoom7/diversifying_my_ira_f...</td>\n",
       "      <td>The more experienced investors recommend a ble...</td>\n",
       "      <td>5</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SirChetManly</td>\n",
       "      <td>kwd6nto</td>\n",
       "      <td>2024-03-25 01:33:43</td>\n",
       "      <td>/r/ETFs/comments/1bmoom7/diversifying_my_ira_f...</td>\n",
       "      <td>It isn't *risky* by any stretch. You're exclud...</td>\n",
       "      <td>2</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZAROV8862</td>\n",
       "      <td>kwei3zo</td>\n",
       "      <td>2024-03-25 06:17:54</td>\n",
       "      <td>/r/ETFs/comments/1bmoom7/diversifying_my_ira_f...</td>\n",
       "      <td>Enough said :))</td>\n",
       "      <td>2</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Financial_Pickle_987</td>\n",
       "      <td>kvqcowi</td>\n",
       "      <td>2024-03-20 21:48:06</td>\n",
       "      <td>/r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...</td>\n",
       "      <td>Lots of downs, lots of ups, but average is aro...</td>\n",
       "      <td>2</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>platskol</td>\n",
       "      <td>kvaljn3</td>\n",
       "      <td>2024-03-17 23:49:51</td>\n",
       "      <td>/r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...</td>\n",
       "      <td>That is a Reddit thing. As soon as people say ...</td>\n",
       "      <td>8</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>phillip_jay</td>\n",
       "      <td>kv9pe1j</td>\n",
       "      <td>2024-03-17 20:01:30</td>\n",
       "      <td>/r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...</td>\n",
       "      <td>Did you read it?</td>\n",
       "      <td>4</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>Rand-Seagull96734</td>\n",
       "      <td>kvhyeh5</td>\n",
       "      <td>2024-03-19 06:54:48</td>\n",
       "      <td>/r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...</td>\n",
       "      <td>Let's say you decided to invest some \"play mon...</td>\n",
       "      <td>1</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Alexchii</td>\n",
       "      <td>kv9pojw</td>\n",
       "      <td>2024-03-17 20:04:20</td>\n",
       "      <td>/r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...</td>\n",
       "      <td>Lol I missed the part where they clearly calle...</td>\n",
       "      <td>1</td>\n",
       "      <td>ETFs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   AUTHOR       ID          CREATED_UTC  \\\n",
       "0              lotterytix  kwh3sji  2024-03-25 20:10:23   \n",
       "1        AlgoTradingQuant  kwczgum  2024-03-25 00:51:21   \n",
       "2         foldinthechhese  kwdbk25  2024-03-25 02:02:08   \n",
       "3            SirChetManly  kwd6nto  2024-03-25 01:33:43   \n",
       "4               ZAROV8862  kwei3zo  2024-03-25 06:17:54   \n",
       "..                    ...      ...                  ...   \n",
       "927  Financial_Pickle_987  kvqcowi  2024-03-20 21:48:06   \n",
       "928              platskol  kvaljn3  2024-03-17 23:49:51   \n",
       "929           phillip_jay  kv9pe1j  2024-03-17 20:01:30   \n",
       "930     Rand-Seagull96734  kvhyeh5  2024-03-19 06:54:48   \n",
       "931              Alexchii  kv9pojw  2024-03-17 20:04:20   \n",
       "\n",
       "                                             PERMALINK  \\\n",
       "0    /r/ETFs/comments/1bmqbxg/new_to_investing_is_v...   \n",
       "1    /r/ETFs/comments/1bmoom7/diversifying_my_ira_f...   \n",
       "2    /r/ETFs/comments/1bmoom7/diversifying_my_ira_f...   \n",
       "3    /r/ETFs/comments/1bmoom7/diversifying_my_ira_f...   \n",
       "4    /r/ETFs/comments/1bmoom7/diversifying_my_ira_f...   \n",
       "..                                                 ...   \n",
       "927  /r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...   \n",
       "928  /r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...   \n",
       "929  /r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...   \n",
       "930  /r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...   \n",
       "931  /r/ETFs/comments/1bgtk4e/voodoo_is_the_sorcery...   \n",
       "\n",
       "                                                  BODY  SCORE SUBREDDIT  \n",
       "0    Maybe consider VOO and a mid/small cap value f...      1      ETFs  \n",
       "1    I’m retired and hold a 100% equities portfolio...      8      ETFs  \n",
       "2    The more experienced investors recommend a ble...      5      ETFs  \n",
       "3    It isn't *risky* by any stretch. You're exclud...      2      ETFs  \n",
       "4                                      Enough said :))      2      ETFs  \n",
       "..                                                 ...    ...       ...  \n",
       "927  Lots of downs, lots of ups, but average is aro...      2      ETFs  \n",
       "928  That is a Reddit thing. As soon as people say ...      8      ETFs  \n",
       "929                                   Did you read it?      4      ETFs  \n",
       "930  Let's say you decided to invest some \"play mon...      1      ETFs  \n",
       "931  Lol I missed the part where they clearly calle...      1      ETFs  \n",
       "\n",
       "[932 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmts_voo = pd.read_csv('../datasets/cleaned_cmts_voo.csv')\n",
    "display(cmts_voo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Cleaned Data into Train, Test and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 349 entries, 104 to 100\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   AUTHOR       349 non-null    object\n",
      " 1   ID           349 non-null    object\n",
      " 2   CREATED_UTC  349 non-null    object\n",
      " 3   PERMALINK    349 non-null    object\n",
      " 4   BODY         349 non-null    object\n",
      " 5   SCORE        349 non-null    int64 \n",
      " 6   SUBREDDIT    349 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 21.8+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 117 entries, 127 to 920\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   AUTHOR       117 non-null    object\n",
      " 1   ID           117 non-null    object\n",
      " 2   CREATED_UTC  117 non-null    object\n",
      " 3   PERMALINK    117 non-null    object\n",
      " 4   BODY         117 non-null    object\n",
      " 5   SCORE        117 non-null    int64 \n",
      " 6   SUBREDDIT    117 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 7.3+ KB\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 466 entries, 17 to 543\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   AUTHOR       466 non-null    object\n",
      " 1   ID           466 non-null    object\n",
      " 2   CREATED_UTC  466 non-null    object\n",
      " 3   PERMALINK    466 non-null    object\n",
      " 4   BODY         466 non-null    object\n",
      " 5   SCORE        466 non-null    int64 \n",
      " 6   SUBREDDIT    466 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 29.1+ KB\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = split_data(cmts_voo)\n",
    "\n",
    "print(train_data.info())\n",
    "print()\n",
    "print(valid_data.info())\n",
    "print()\n",
    "print(test_data.info())\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Transformer Model in Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using ```BERT-Base-Uncased``` model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```BERT```: BERT stands for Bidirectional Encoder Representations from Transformers. It's a groundbreaking model introduced by Google in 2018 that revolutionized the field of natural language processing (NLP). BERT is known for its deep understanding of language context, which it achieves through its transformer architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Base```: The \"base\" in \"bert-base-uncased\" indicates the size of the model. BERT typically comes in two sizes: base and large. The base model is smaller and faster, making it more practical for many applications, though the large model generally performs better on NLP tasks. The base model has 110 million parameters, while the large model has 340 million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Uncased```: This specifies that the model was trained on text that has been converted to lowercase, meaning the model does not differentiate between uppercase and lowercase letters. This is in contrast to a \"cased\" model, which is sensitive to letter casing. For instance, in a cased model, \"Hello\" and \"hello\" would be treated differently, whereas they would be treated the same in an uncased model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer we used here is ```AutoTokenizer``` from ```Hugging Face```. \n",
    "More detail can check at https://huggingface.co/docs/transformers/v4.39.2/en/autoclass_tutorial#autotokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(transformer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of tokenization and numericalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we', 'are', 'doing', 'sentiment', 'analysis', '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"We are doing sentiment analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2057, 2024, 2725, 15792, 4106, 999, 102]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"We are doing sentiment analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'we', 'are', 'doing', 'sentiment', 'analysis', '!', '[SEP]']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(tokenizer.encode(\"We are doing sentiment analysis!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2057, 2024, 2725, 15792, 4106, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"We are doing sentiment analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_index = tokenizer.pad_token_id\n",
    "batch_size = 8\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are using the transformer model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
